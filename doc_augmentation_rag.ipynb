{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347952c4",
   "metadata": {},
   "source": [
    "# 文档增强与问题生成\n",
    "为文本chunk生成相关问题，提高检索过程\n",
    "提取文档、分块、**生成问题**、chunk与问题嵌入、向量存储、语义搜索、响应生成、评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4c3728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import numpy as np\n",
    "import json\n",
    "from zhipuai import ZhipuAI\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53144cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"AI_Information.en.zh-CN.pdf\"\n",
    "API_KEY = \"f532b4bd71324c1ca2fd7e22d4eb41da.4Sfpr8wE6qEVV5BY\"\n",
    "# 设置客户端,处理文本\n",
    "client = ZhipuAI(api_key = API_KEY) \n",
    "\n",
    "# model\n",
    "llm_model = \"glm-4\"\n",
    "embedding_model=\"embedding-3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67781b6c",
   "metadata": {},
   "source": [
    "**提取文本识别章节标题**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5100e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    # 打开 PDF 文件\n",
    "    mypdf = fitz.open(pdf_path)\n",
    "    all_text = \"\"  # 初始化一个空字符串以存储提取的文本\n",
    "\n",
    "    # Iterate through each page in the PDF\n",
    "    for page_num in range(mypdf.page_count):\n",
    "        page = mypdf[page_num]\n",
    "        text = page.get_text(\"text\")  # 从页面中提取文本\n",
    "        all_text += text  # 将提取的文本追加到 all_text 字符串中\n",
    "\n",
    "    return all_text  # 返回提取的文本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c230d34",
   "metadata": {},
   "source": [
    "**提取文本分块**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "577d0352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, n, overlap):\n",
    "    chunks = []  #\n",
    "    for i in range(0, len(text), n - overlap):\n",
    "        # 添加从当前索引到索引 + 块大小的文本块\n",
    "        chunks.append(text[i:i + n])\n",
    "\n",
    "    return chunks  # Return the list of text chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfaa77a",
   "metadata": {},
   "source": [
    "**对每个文本块生成可以通过该文本回答的问题**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df4b055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions(text_chunk, num_questions=5):\n",
    "    \"\"\"\n",
    "    生成可以从给定文本块中回答的相关问题。\n",
    "\n",
    "    Args:\n",
    "    text_chunk (str): 要生成问题的文本块。\n",
    "    num_questions (int): 要生成的问题数量。\n",
    "    model (str): 用于生成问题的模型。\n",
    "\n",
    "    Returns:\n",
    "    List[str]: 生成的问题列表。\n",
    "    \"\"\"\n",
    "    # 定义系统提示\n",
    "    system_prompt = \"你是一个从文本中生成相关问题的专家。能够根据用户提供的文本生成可回答的简洁问题，重点聚焦核心信息和关键概念。\"\n",
    "\n",
    "    # 定义用户提示，包含文本块和要生成的问题数量\n",
    "    # user_prompt = f\"\"\"\n",
    "    # 根据以下文本，生成 {num_questions} 个不同的问题，这些问题只能通过此文本回答：\n",
    "    #\n",
    "    # {text_chunk}\n",
    "    #\n",
    "    # 请以编号列表的形式回复问题，且不要添加任何额外文本。\n",
    "    # \"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "    请根据以下文本内容生成{num_questions}个不同的、仅能通过该文本内容回答的问题：\n",
    "\n",
    "    {text_chunk}\n",
    "\n",
    "    请严格按以下格式回复：\n",
    "    1. 带编号的问题列表\n",
    "    2. 仅包含问题\n",
    "    3. 不要添加任何其他内容\n",
    "    \"\"\"\n",
    "\n",
    "    # 使用 API 生成问题\n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_model,\n",
    "        temperature=0.7,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 从响应中提取并清理问题\n",
    "    questions_text = response.choices[0].message.content.strip()\n",
    "\n",
    "    # 使用正则表达式模式匹配提取问题\n",
    "    # pattern = r'^\\d+\\.\\s*(.*)'\n",
    "    # return [re.match(pattern, line).group(1) for line in questions_text.split('\\n') if line.strip()]\n",
    "    questions = []\n",
    "    for line in questions_text.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "            \n",
    "        # 检查行是否以数字开头\n",
    "        if line[0].isdigit():\n",
    "            # 查找第一个非数字和非标点符号的位置\n",
    "            for i, char in enumerate(line):\n",
    "                if not (char.isdigit() or char in '.)'):\n",
    "                    break\n",
    "            # 提取问题内容（跳过编号和标点）\n",
    "            question = line[i:].strip()\n",
    "            if question:\n",
    "                questions.append(question)\n",
    "        else:\n",
    "            # 如果行不以数字开头，可能是没有编号的问题\n",
    "            questions.append(line)\n",
    "    \n",
    "    return questions[:num_questions] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46ab61f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从 PDF 中提取文本...\n",
      "分割文本...\n",
      "创建了 13 个文本块\n",
      "处理文本块并生成问题...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文本块:   0%|          | 0/13 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Questions:\n",
      "['人工智能指的是什么能力？', '人工智能研究的正式领域始于哪个世纪？', '1956年的哪个会议被认为是人工智能的发源地？', '监督学习算法是如何进行训练的？', '深度学习使用什么来分析数据？']\n",
      "--------------------------------------生成问题--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 测试生成的问题\n",
    "\n",
    "print(\"从 PDF 中提取文本...\")\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "print(\"分割文本...\")\n",
    "text_chunks = chunk_text(extracted_text, 1000, 200)\n",
    "print(f\"创建了 {len(text_chunks)} 个文本块\")\n",
    "\n",
    "print(\"处理文本块并生成问题...\")\n",
    "\n",
    "for i, chunk in enumerate(tqdm(text_chunks, desc=\"处理文本块\")):\n",
    "    questions = generate_questions(chunk, num_questions=5)\n",
    "    print(\"Generated Questions:\")\n",
    "    print(questions)\n",
    "    print(\"生成问题\".center(80, '-'))\n",
    "\n",
    "    if i == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b314534",
   "metadata": {},
   "source": [
    "**文本嵌入** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f96be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(text):\n",
    "    \"\"\"\n",
    "    为给定文本创建嵌入向量，使用指定的 zhipu 模型。\n",
    "\n",
    "    Args:\n",
    "    text (str): 要为其创建嵌入向量的输入文本。\n",
    "    model (str): 用于创建嵌入向量的模型。\n",
    "\n",
    "    Returns:\n",
    "    response: 包含嵌入向量的 zhipu API 响应。\n",
    "    \"\"\"\n",
    "    # 使用指定模型为输入文本创建嵌入向量\n",
    "    response = client.embeddings.create(\n",
    "        model=embedding_model,\n",
    "        input=text\n",
    "    )\n",
    "\n",
    "    return response  # 返回包含嵌入向量的响应"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c31ba7a",
   "metadata": {},
   "source": [
    "**定义新的向量存储**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aab84fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVectorStore:\n",
    "    def __init__(self):\n",
    "        self.vectors = []  # 存储嵌入向量的列表\n",
    "        self.texts = []  # 存储对应文本的列表\n",
    "        self.metadata = []  # 存储元数据的列表\n",
    "\n",
    "    def add_item(self, text, embedding, metadata=None):\n",
    "        \"\"\"\n",
    "        添加一个文本、其嵌入向量和可选的元数据到存储中。\n",
    "\n",
    "        Args:\n",
    "        text (str): 要存储的文本。\n",
    "        embedding (List[float]): 文本的嵌入向量。\n",
    "        metadata (dict, optional): 相关的元数据。\n",
    "        \"\"\"\n",
    "        self.texts.append(text)\n",
    "        self.vectors.append(np.array(embedding))  # 确保嵌入向量是 NumPy 数组\n",
    "        self.metadata.append(metadata if metadata else {})\n",
    "\n",
    "    def similarity_search(self, query_embedding, k=5):\n",
    "        \"\"\"\n",
    "        执行相似性搜索，返回与查询嵌入向量最相似的文本。\n",
    "\n",
    "        Args:\n",
    "        query_embedding (List[float]): 查询的嵌入向量。\n",
    "        top_k (int): 返回的最相似文本的数量。\n",
    "\n",
    "        Returns:\n",
    "        List[Dict]: 包含最相似文本及其相似度分数的列表。\n",
    "        \"\"\"\n",
    "        if not self.vectors:\n",
    "            return []\n",
    "        \n",
    "        # 转换查询嵌入向量\n",
    "        query_vector = np.array(query_embedding)\n",
    "\n",
    "        # 相似度计算\n",
    "        similarities = []\n",
    "        for i,vector in enumerate(self.vectors):\n",
    "            similarity = np.dot(vector, query_vector) / (np.linalg.norm(query_vector) * np.linalg.norm(vector))\n",
    "            similarities.append((i,similarity))\n",
    "\n",
    "        # 相似度排序\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)  # 按相似度降序排序\n",
    "        results = []\n",
    "        for i in range(min(k, len(similarities))):  # 确保不会超出向量数量\n",
    "            idx, score = similarities[i]\n",
    "            results.append({\n",
    "                \"text\": self.texts[idx],  # 对应的文本\n",
    "                \"metadata\": self.metadata[idx],  # 对应的元数据\n",
    "                \"similarity\": score  # 相似度分数\n",
    "            })\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46dc156",
   "metadata": {},
   "source": [
    "**使用问题增强处理文档，整合步骤处理文档、生成问题，构建增强向量存储**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db8cede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(pdf_path, chunk_size=1000, chunk_overlap=200, questions_per_chunk=5):\n",
    "    \"\"\"\n",
    "    处理结合了生成问题的文档，结合之前的重叠等方法。\n",
    "\n",
    "    Args:\n",
    "    pdf_path (str): PDF 文件的路径。\n",
    "    chunk_size (int): 每个文本块的字符大小。\n",
    "    chunk_overlap (int): 块之间的重叠字符数。\n",
    "    questions_per_chunk (int): 每个块生成的问题数量。\n",
    "\n",
    "    Returns:\n",
    "    Tuple[List[str], SimpleVectorStore]: 文本块列表和向量存储。\n",
    "    \"\"\"\n",
    "    print(\"从 PDF 中提取文本...\")\n",
    "    extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    print(\"分割文本...\")\n",
    "    text_chunks = chunk_text(extracted_text, chunk_size, chunk_overlap)\n",
    "    print(f\"创建了 {len(text_chunks)} 个文本块\")\n",
    "\n",
    "    # 初始化向量存储\n",
    "    # print(\"初始化向量存储...\")\n",
    "    vector_store = SimpleVectorStore()\n",
    "\n",
    "    print(\"处理文本块并生成问题...\")\n",
    "    for i, chunk in enumerate(tqdm(text_chunks, desc=\"处理文本块\")):\n",
    "        # 为文本块本身创建嵌入\n",
    "        chunk_embedding_response = create_embeddings(chunk)\n",
    "        chunk_embedding = chunk_embedding_response.data[0].embedding\n",
    "\n",
    "        # 将文本块添加到向量存储中\n",
    "        vector_store.add_item(\n",
    "            text=chunk,\n",
    "            embedding=chunk_embedding,\n",
    "            metadata={\"type\": \"chunk\", \"index\": i}\n",
    "        )\n",
    "\n",
    "        # 为该文本块生成问题\n",
    "        questions = generate_questions(chunk, num_questions=questions_per_chunk)\n",
    "\n",
    "        # 为每个问题创建嵌入并添加到向量存储中\n",
    "        for j, question in enumerate(questions):\n",
    "            question_embedding_response = create_embeddings(question)\n",
    "            question_embedding = question_embedding_response.data[0].embedding\n",
    "\n",
    "            # 将问题添加到向量存储中\n",
    "            vector_store.add_item(\n",
    "                text=question,\n",
    "                embedding=question_embedding,\n",
    "                metadata={\"type\": \"question\", \"chunk_index\": i, \"original_chunk\": chunk}\n",
    "            )\n",
    "\n",
    "    return text_chunks, vector_store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcad44dc",
   "metadata": {},
   "source": [
    "**文档处理**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "332a4608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从 PDF 中提取文本...\n",
      "分割文本...\n",
      "创建了 13 个文本块\n",
      "处理文本块并生成问题...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文本块: 100%|██████████| 13/13 [00:53<00:00,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量存储包含 52 个项目\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 处理文档（提取文本、创建块、生成问题、构建向量存储）\n",
    "text_chunks, vector_store = process_document(\n",
    "    pdf_path,\n",
    "    chunk_size=1000,  # 每个文本块的字符大小为1000\n",
    "    chunk_overlap=200,  # 块之间的重叠字符数为200\n",
    "    questions_per_chunk=3  # 每个块生成3个问题\n",
    ")\n",
    "\n",
    "# 打印向量存储中的项目数量\n",
    "print(f\"向量存储包含 {len(vector_store.texts)} 个项目\")  # 13*4=52，一个块由1个chunk,3个question组成\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90fcabf",
   "metadata": {},
   "source": [
    "**增强向量存储的语音检索增强生成**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7d840206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, vector_store, k=5):\n",
    "    \"\"\"\n",
    "    使用查询和向量存储执行语义搜索。\n",
    "\n",
    "    Args：\n",
    "    query (str): 搜索查询。\n",
    "    vector_store (SimpleVectorStore): 要搜索的向量存储。\n",
    "    k (int): 返回的结果数量。\n",
    "\n",
    "    Returns：\n",
    "    List[Dict]: 最相关的前 k 个结果列表，每个结果包含文本和元数据信息。\n",
    "    \"\"\"\n",
    "    # 为查询创建嵌入\n",
    "    query_embedding_response = create_embeddings(query)\n",
    "    query_embedding = query_embedding_response.data[0].embedding\n",
    "\n",
    "    # 搜索向量存储\n",
    "    results = vector_store.similarity_search(query_embedding, k=k)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328760e5",
   "metadata": {},
   "source": [
    "**向量存储中检索问题、生成**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b6216f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 与人工智能驱动的人脸识别相关的伦理问题有哪些？\n",
      "\n",
      "Search Results:\n",
      "\n",
      "Relevant Document Chunks:\n",
      "\n",
      "Matched Questions:\n",
      "Question 1 (similarity: 0.6627):\n",
      "在人工智能安全与保障方面，研究的关键点是什么？\n",
      "From chunk 9\n",
      "=====================================\n",
      "Question 2 (similarity: 0.6499):\n",
      "在负责任地开发和部署人工智能中，需要遵守哪些原则？\n",
      "From chunk 12\n",
      "=====================================\n",
      "Question 3 (similarity: 0.6438):\n",
      "在人工智能发展中，为什么需要建立指导方针和道德框架？\n",
      "From chunk 3\n",
      "=====================================\n",
      "Question 4 (similarity: 0.6414):\n",
      "什么是以人为本的人工智能方法？\n",
      "From chunk 12\n",
      "=====================================\n",
      "Question 5 (similarity: 0.6215):\n",
      "人工智能在人力资源领域有哪些具体应用？\n",
      "From chunk 5\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "# 测试语义搜索\n",
    "with open(\"val.json\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 随机测试\n",
    "random_index = random.randint(0, len(data) - 1)\n",
    "query = data[2][\"question\"]\n",
    "\n",
    "# 执行语义搜索\n",
    "search_results = semantic_search(query, vector_store, k=5)\n",
    "\n",
    "print(\"Query:\", query)  # 打印查询内容\n",
    "print(\"\\nSearch Results:\")  # 打印搜索结果标题\n",
    "\n",
    "chunk_results = []  # 文档块的结果\n",
    "question_results = []  # 问题的结果\n",
    "\n",
    "for result in search_results:\n",
    "    if result[\"metadata\"][\"type\"] == \"chunk\":  # 如果结果是文档块类型\n",
    "        chunk_results.append(result)\n",
    "    else:  # 如果结果是问题类型\n",
    "        question_results.append(result)\n",
    "\n",
    "# 打印文档块结果\n",
    "print(\"\\nRelevant Document Chunks:\")  # 打印相关文档块标题\n",
    "for i, result in enumerate(chunk_results):\n",
    "    print(f\"Context {i + 1} (similarity: {result['similarity']:.4f}):\")  # 打印每个文档块的相似度分数\n",
    "    print(result[\"text\"][:300] + \"...\")  # 打印文档块的前300个字符\n",
    "    print(\"=====================================\")  # 分隔符\n",
    "\n",
    "# 打印匹配的问题\n",
    "print(\"\\nMatched Questions:\")  # 打印匹配问题标题\n",
    "for i, result in enumerate(question_results):\n",
    "    print(f\"Question {i + 1} (similarity: {result['similarity']:.4f}):\")  # 打印每个问题的相似度分数\n",
    "    print(result[\"text\"])  # 打印问题内容\n",
    "    chunk_idx = result[\"metadata\"][\"chunk_index\"]  # 获取问题所属的文档块索引\n",
    "    print(f\"From chunk {chunk_idx}\")  # 打印问题来源的文档块索引\n",
    "    print(\"=====================================\")  # 分隔符\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb89c73",
   "metadata": {},
   "source": [
    "**结合文档块、问题准备回答的上下文**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7aa097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_context_for_answering(search_results):\n",
    "    \"\"\"\n",
    "    从语义搜索中准备回答问题的上下文。\n",
    "\n",
    "    Args:\n",
    "    search_results (List[Dict]): 语义搜索的结果。\n",
    "\n",
    "    Returns:\n",
    "    str: 准备好的上下文字符串。\n",
    "    \"\"\"\n",
    "    # 结果中独特文档块\n",
    "    chunk_indices = set()\n",
    "    context_chunks = []\n",
    "\n",
    "    # 添加直接匹配的文档块\n",
    "    for result in search_results:\n",
    "        if result[\"metadata\"][\"type\"] == \"chunk\":\n",
    "            chunk_indices.add(result[\"metadata\"][\"index\"])\n",
    "            context_chunks.append(f\"Chunk {result['metadata']['index']}:\\n{result['text']}\")\n",
    "\n",
    "    # 添加问题引用的文档块\n",
    "    for result in search_results:\n",
    "        if result[\"metadata\"][\"type\"] == \"question\":\n",
    "            chunk_idx = result[\"metadata\"][\"chunk_index\"]\n",
    "            if chunk_idx not in chunk_indices:\n",
    "                chunk_indices.add(chunk_idx)\n",
    "                context_chunks.append(\n",
    "                    f\"Chunk {chunk_idx} (referenced by question '{result['text']}'):\\n{result['metadata']['original_chunk']}\")\n",
    "\n",
    "    # 合并上下文块\n",
    "    full_context = \"\\n\\n\".join(context_chunks)\n",
    "    return full_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85db1e2b",
   "metadata": {},
   "source": [
    "**根据检索上下文生成回答**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b3581319",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, context):\n",
    "    # 定义系统提示，指导zhipu严格基于给定的上下文进行回答。\n",
    "    # 如果无法从上下文回复，应该说不知道而不是瞎说\n",
    "    system_prompt = \"你是一个AI助手，严格根据给定的上下文进行回答。如果无法直接从提供的上下文中得出答案，请回复：'我没有足够的信息来回答这个问题。'\"\n",
    "\n",
    "    # 使用上下文和问题定义用户提示\n",
    "    user_prompt = f\"\"\"\n",
    "        上下文内容:\n",
    "        {context}\n",
    "\n",
    "        问题: {query}\n",
    "\n",
    "        请仅根据上述上下文回答问题, 并保持简明扼要。\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_model,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content  # 返回生成的回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "967d9eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: 与人工智能驱动的人脸识别相关的伦理问题有哪些？\n",
      "\n",
      "Response:\n",
      "与人工智能驱动的人脸识别相关的伦理问题包括隐私权、数据保护、公平性和透明度。具体而言，人脸识别技术可能会未经个人同意收集和利用个人生物识别信息，这侵犯了隐私权；此外，若数据管理不当，可能会导致敏感信息泄露，引发数据保护问题。还有，人脸识别系统可能存在算法偏见，对不同人群的识别准确性和公平性存疑，缺乏透明度也会使得系统的决策过程难以接受公众监督。\n"
     ]
    }
   ],
   "source": [
    "# 准备上下文\n",
    "context = prepare_context_for_answering(search_results)\n",
    "\n",
    "# 生成回答\n",
    "response = generate_response(query, context)\n",
    "\n",
    "print(\"\\nQuery:\", query)\n",
    "print(\"\\nResponse:\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f0d12b",
   "metadata": {},
   "source": [
    "**eval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "291f7202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:\n",
      "根据提供的参考答案，以下是对AI回答的评估：\n",
      "\n",
      "1. 事实正确性：AI回答提到了人脸识别技术涉及的主要伦理问题，如隐私权、数据保护、公平性和透明度，这些都是当前关于人脸识别伦理讨论中的关键议题。参考答案虽然提到了可解释人工智能（XAI），但并未直接列举人脸识别的伦理问题。因此，AI的回答在事实正确性方面是符合要求的。\n",
      "   评分：0.8\n",
      "\n",
      "2. 完整性：AI回答较为全面地概述了人脸识别技术的伦理问题，包括多个重要方面。虽然它没有提到“可解释人工智能”（XAI）这一特定术语，但其所提及的透明度和公平性实际上与XAI的概念有所重叠。因此，在完整性方面，AI回答做得相对较好。\n",
      "   评分：0.7\n",
      "\n",
      "3. 相关性：AI的回答直接针对了问题，即人脸识别相关的伦理问题，与问题的主题紧密相关。\n",
      "   评分：1.0\n",
      "\n",
      "综合评分：根据以上三个标准，综合评分为：(0.8 + 0.7 + 1.0) / 3 = 0.833\n",
      "\n",
      "理由说明：\n",
      "- AI的回答在事实正确性方面做得很好，涵盖了人脸识别技术的主要伦理问题。\n",
      "- 在完整性方面，虽然AI回答没有涵盖参考答案中提到的“可解释人工智能”这一术语，但其内容仍然包括了与该术语相关的概念，因此只轻微扣分。\n",
      "- 在相关性方面，AI的回答完全符合问题要求，直接回应了问题。\n",
      "\n",
      "因此，综合考虑，AI的回答质量是较高的。\n"
     ]
    }
   ],
   "source": [
    "def evaluate_response(query, response, reference_answer):\n",
    "    \"\"\"\n",
    "    对AI生成的回答进行评估，将其与参考答案进行对比。\n",
    "\n",
    "    Args:\n",
    "    query (str): 用户的问题。\n",
    "    response (str): AI生成的回答。\n",
    "    reference_answer (str): 参考/理想答案。\n",
    "    model (str): 用于评估的模型。\n",
    "\n",
    "    Returns:\n",
    "    str: 评估反馈。\n",
    "    \"\"\"\n",
    "    # 定义评估系统的系统提示\n",
    "    evaluate_system_prompt = \"\"\"您是一个智能评估系统，负责评估AI回答的质量。\n",
    "    请将AI助手的回答与真实/参考答案进行对比，基于以下几点进行评估：\n",
    "        1. 事实正确性 - 回答是否包含准确信息？\n",
    "        2. 完整性 - 是否涵盖参考内容的所有重要方面？\n",
    "        3. 相关性 - 是否直接针对问题作出回应？\n",
    "\n",
    "        请分配0到1之间的评分：\n",
    "        - 1.0：内容与含义完全匹配\n",
    "        - 0.8：非常好，仅有少量遗漏/差异\n",
    "        - 0.6：良好，涵盖主要要点但遗漏部分细节\n",
    "        - 0.4：部分正确答案但存在显著遗漏\n",
    "        - 0.2：仅包含少量相关信息\n",
    "        - 0.0：错误或无关信息\n",
    "\n",
    "    请提供评分并附理由说明。\n",
    "    \"\"\"\n",
    "\n",
    "    # 创建评估提示\n",
    "    # 包含用户问题、AI回答、参考答案以及要求评估的内容。\n",
    "    evaluation_prompt = f\"\"\"\n",
    "        用户问题: {query}\n",
    "\n",
    "        AI回答:\n",
    "        {response}\n",
    "\n",
    "        参考答案:\n",
    "        {reference_answer}\n",
    "\n",
    "        请根据参考答案评估AI的回答。\n",
    "    \"\"\"\n",
    "\n",
    "    # 生成评估结果\n",
    "    # 使用指定的模型生成评估结果。\n",
    "    eval_response = client.chat.completions.create(\n",
    "        model=llm_model,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": evaluate_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": evaluation_prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 返回评估内容\n",
    "    return eval_response.choices[0].message.content\n",
    "\n",
    "reference_answer = data[0]['ideal_answer']\n",
    "\n",
    "evaluation = evaluate_response(query, response, reference_answer)\n",
    "\n",
    "print(\"\\nEvaluation:\")\n",
    "print(evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
